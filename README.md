# JARVIS ğŸ¤–  
**A Local, Autonomous AI Assistant with Memory, Self-Review, and Tool Execution**

JARVIS is a full-stack autonomous AI assistant inspired by the idea of a true AI operating layer â€” not just a chatbot.

Unlike typical AI demos, JARVIS is designed as a **real system** that can:
- Understand high-level goals
- Plan tasks using an LLM
- Execute actions using tools
- Review its own output
- Persist memory across runs
- Operate fully **offline** using a **local LLM (Ollama)**

---

## ğŸš€ Key Features

### ğŸ§  Autonomous Reasoning
- Goal-based planning using a local LLM
- Breaks vague goals into ordered, executable steps

### ğŸ§‘â€ğŸ¤â€ğŸ§‘ Multi-Agent Architecture
- **Planner Agent** â€“ decomposes goals into steps  
- **Executor Agent** â€“ executes steps and tools  
- **Reviewer Agent** â€“ validates output quality before acceptance  

### ğŸ’¾ Memory System
- **Short-term memory** (per execution)
- **Long-term memory** (persistent across runs)
- Approved results are automatically stored

### ğŸ› ï¸ Tool Execution (Safe by Design)
- LLM decides **which tool to use**
- Strictly sandboxed tools:
  - File reading (project directory only)
  - Shell commands (allow-listed only)
- Hard safety guardrails (no arbitrary execution)

### ğŸ” Reliability
- Retry logic on failed steps
- Defensive handling of LLM errors
- No crashes on malformed responses

### ğŸ”’ Privacy-First
- Runs **entirely locally**
- No OpenAI / paid APIs
- Uses Ollama + open-source models (Mistral, LLaMA, etc.)

---

## ğŸ—ï¸ Architecture Overview

User Goal
â†“
JARVIS Agent
â”œâ”€â”€ Planner Agent (LLM)
â”œâ”€â”€ Executor Agent
â”‚ â””â”€â”€ Tool Router (LLM)
â”‚ â”œâ”€â”€ File Tool
â”‚ â””â”€â”€ Shell Tool
â”œâ”€â”€ Reviewer Agent (LLM)
â””â”€â”€ Memory System
â”œâ”€â”€ Short-Term
â””â”€â”€ Long-Term


---

## ğŸ“‚ Project Structure

jarvis/
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ agent.py # Main control loop
â”‚ â”œâ”€â”€ planner.py # LLM-based planning
â”‚ â”œâ”€â”€ executor.py # Step execution + tool usage
â”‚ â”œâ”€â”€ reviewer.py # LLM-based self-review
â”‚ â”œâ”€â”€ router.py # Tool selection logic
â”‚ â””â”€â”€ llm.py # Local LLM abstraction (Ollama)
â”‚
â”œâ”€â”€ tools/
â”‚ â”œâ”€â”€ registry.py # Tool registry
â”‚ â”œâ”€â”€ file_tool.py # Safe file reader
â”‚ â””â”€â”€ shell_tool.py # Safe shell execution
â”‚
â”œâ”€â”€ memory/
â”‚ â”œâ”€â”€ short_term.py # Session memory
â”‚ â””â”€â”€ long_term.py # Persistent memory
â”‚
â”œâ”€â”€ security/ # Reserved for future guardrails
â”œâ”€â”€ main.py # Entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸ§  Local LLM Setup (Required)

JARVIS uses **Ollama** for local LLM inference.

### Install Ollama
```bash
curl -fsSL https://ollama.com/install.sh | sh

## Pull a Model (Recommended)
ollama pull mistral:7b

